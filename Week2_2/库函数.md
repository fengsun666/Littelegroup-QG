# 库函数（作业中已用）

## sklearn库

### 1.train_test_split

```python
#将数组或矩阵切分为随机训练和测试子集
sklearn.model_selection.train_test_split(*arrays,test_size=None,train_size=None,                                         random_state=None,shuffle=True,stratify=None)
```

==*array==:允许输入列表，numpy数组，scipy-sparse矩阵或pandas dataframes
==test_size,train_size==:
类型：**int**或**float**;
若为float,表示要包含在测试（训练）拆分中的数据集的比例。若为int，表示测试（训练）样本的绝对数量。若为None,设为训练（测试）尺寸的补码。

==random_state==:

类型：**bool**

拆分前是否对数据进行随机排序，默认为真。



***

### 2.LinearRegression

```python
#普通最小二乘线性回归。线性回归拟合系数为 w = （w1， ...， wp） 的线性模型最小化观测目标之间的残差平方和数据集，以及由线性近似预测的目标。
sklearn.linear_model.LinearRegression(*,fit_intercept=True,copy_X=True,n_jobs=None,
                                      positive=False)
```

==copy_X==:默认为True,复制X。False则可能被覆盖。



****

### 3.MSE和MAE

```python
mean_squared_error(MSE)
#预测值与真实值之间距离的平方和
sklearn.metrics.mean_squared_error(y_true,y_pred,*,sample_weight=None,
                                   multioutput='uniform_average',squared=True)
```

==y_true==:真实值        ==y_pred==:预测值

<img src="https://picx.zhimg.com/v2-fb050ce4ead1de75aa1b67294d3d2add_1440w.jpg?source=172ae18b" alt="MSE" style="zoom:25%;" />

<img src="https://pic2.zhimg.com/80/v2-00dbd4433986f10e9426559aa0b32f35_720w.webp" alt="MSE2" style="zoom:33%;" />

优点：**==MSE==**的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。 而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。
缺点：当真实值y和预测值f(x)的==差值大于1==时，会放大误差；而当==差值小于1==时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差(>1)给予较大的惩罚，较小的误差(<1）给予较小的惩罚。也就是说，==对离群点比较敏感==，受其影响较大。

```python
mean_absolute_error(MAE)#也称L1损失函数
#目标值和预测值之差的绝对值之和。
sklearn.metrics.mean_absolute_error(y_true,y_pred,*,sample_weight=None,
                                    multioutput='uniform_average')
```

==y_true==:真实值        ==y_pred==:预测值

![MAE1](https://image.jiqizhixin.com/uploads/editor/bd4624ba-f00c-42aa-b06d-374b74aae671/1529558773392.png)

优点：相比于MSE，**==MAE==**有个优点就是，对于离群点不那么敏感。因为MAE计算的是误差(y-f(x))的绝对值，对于任意大小的差值，其惩罚都是固定的。无论对于什么样的输入值，都有着==稳定的梯度==，不会导致梯度爆炸问题，具有较为稳健性的解。
缺点：MAE曲线连续，但是在(y-f(x)=0)处不可导。而且 MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。



***

### 4.StandardScaler

```python
#通过移除均值并缩放到单位方差来标准化特征。
sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)
```

==copy==:如果为 False，请尝试避免复制并改为就地缩放。

==with_mean==:如果为 True，则在缩放之前将数据居中。

==with_std==:如果为 True，则将数据缩放为单位方差(或单位标准差)。

==**作用**==：去均值和方差归一化。且是针对每一个特征维度来做的，而不是针对样本。 

标准差标准化（standardScale）使得经过处理的数据符合标准正态分布，即均值为0，标准差为1，其转化函数为

![标准差正态分布](https://img-blog.csdnimg.cn/20190525174040159.png)

其中μ为所有样本数据的均值，σ为所有样本数据的标准差。



****

### 5.f_regression

```python
#单变量线性回归测试。一种线性模型，用于测试多个回归因子中每一个的单独效果。这是用于特征选择程序的评分函数，而不是独立的特征选择程序。
sklearn.feature_selection.f_regression(X, y, *, center=True, force_finite=True)
#1.计算每个回归变量与目标之间的相关性.
#2.将其转换为F分数，然后转换为p值。
```

==x==:将依次测试的一组回归变量集合。        ==y==:数据矩阵。

==center==:如果为true，则X和y将居中。



***

### 6.SelectKBest

```python
#根据k个最高分数选择功能.
sklearn.feature_selection.SelectKBest(score_func=<function f_classif>, *, k=10)
```

==score_func==:函数接受两个数组X和y，并返回一对数组（分数，p值）或带分数的单个数组。

默认值为f_classif [计算样本的ANOVA F值。]

==k==:int 或 “all”， 可选， default=10.k指要选择的主要功能数。“ all”选项绕过选择，用于参数搜索。



***

### 7.R2_score和RMSE

#### R2_score

```python
#R^2（确定系数）回归得分函数。（R2_score）
sklearn.metrics.r2_score(y_true,y_pred,*,sample_weight=None,
                         multioutput='uniform_average')
#R2_score = 1，样本中预测值和真实值完全相等，没有任何误差，表示回归分析中自变量对因变量的解释越好。
#R2_score = 0。此时分子等于分母，样本的每项预测值都等于均值。
```

==回归平方和==：*SSR*。估计值与平均值的误差，反映自变量与因变量之间的相关程度的偏差平方和

<img src="https://math.jianshu.com/math?formula=SSR%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bn%7D(%5Chat%7By_i%7D%20-%20%5Cbar%7By%7D)%5E2" alt="ssr" style="zoom: 80%;" />

==残差平方和==：*SSE*。估计值与真实值的误差，反映模型拟合程度

<img src="https://math.jianshu.com/math?formula=SSE%20%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bn%7D(y_i-%5Chat%7By_i%7D%20)%5E2" alt="sse" style="zoom:80%;" />

==总离差平方和==：*SST*。平均值与真实值的误差，反映与数学期望的偏离程度

<img src="https://math.jianshu.com/math?formula=SST%20%3DSSR%20%2B%20SSE%3D%20%5Csum_%7Bi%3D1%7D%5E%7Bn%7D(y_i%20-%20%5Cbar%7By%7D)%5E2" alt="sst" style="zoom:80%;" />

**==R2_score==**:

<img src="https://math.jianshu.com/math?formula=R%5E2%3D1-%5Cfrac%7BSSE%7D%7BSST%7D" alt="r2" style="zoom:80%;" />

也即

<img src="https://math.jianshu.com/math?formula=R%5E2%20%3D%201%20-%20%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By%7D_i)%5E2%7D%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20(y_i%20-%20%5Cbar%7By%7D)%5E2%7D" alt="r2-1" style="zoom:80%;" />

#### RMSE(均方根误差)

Root Mean Square Error

<img src="https://img-blog.csdnimg.cn/20200207165105791.png" alt="rmse" style="zoom:80%;" />



****







## matplotlib库

### 1.plot

```python
#将y与x绘制为线条或标记.
matplotlib.pyplot.plot(*args, scalex=True, scaley=True, data=None, **kwargs)
```

==x&y==:数组或标量。   ==scalex&scaley==:确定视图限制是否适应数据限制。

==**kwargs==:指定属性，如线标签、线宽、抗锯齿、标记面颜色。

```python
#'b'蓝  'g'绿  'r'红  'c'青  'm'品红  'y'黄  'k'黑  'w'白
#'.'点标记  ','像素标记  'o'圆圈标记  '-'实线样式  '--'虚线样式  '-.'点线样式  ':'虚线样式
```

****



### 2.figure

```python
#绘图
plot.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True)
```

==num==:图像编号或名称，数字为编号 ，字符串为名称
==figsize==:指定figure的宽和高，单位为英寸；
==dpi==参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80 1英寸等于2.5cm,A4纸是 21*30cm的纸张
==facecolor==:背景颜色
==edgecolor==:边框颜色
==frameon==:是否显示边框

****



### 3.subplots





****



### 4.subplots_adjust

```python
#调整子图布局。
matplotlib.pyplot.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)
```

==left==：所有子图整体相对于图像的**左外边距**，距离单位为图像宽度的比例（小数）。可选参数。浮点数。默认值为0.125。
==right==：所有子图整体相对于图像的**右外边距**，距离单位为图像宽度的比例（小数）。可选参数。浮点数。默认值为0.0。
==bottom==：所有子图整体相对于图像的**下外边距**，距离单位为图像高度的比例（小数）。可选参数。浮点数。默认值为0.11。
==top==：所有子图整体相对于图像的**上外边距**，距离单位为图像高度的比例（小数）。可选参数。浮点数。默认值为0.88。
==wspace==：子图间**宽度内边距**，距离单位为子图平均宽度的比例（小数）。浮点数。默认值为0.2。
==hspace==：子图间**高度内边距**，距离单位为子图平均高度的比例（小数）。可选参数。浮点数。默认值为0.2。

<img src="https://img-blog.csdnimg.cn/20190328213224823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dndDU1bmc2,size_16,color_FFFFFF,t_70#pic_center" alt="sub" style="zoom: 50%;" />

<img src="https://img-blog.csdnimg.cn/20190328214315795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dndDU1bmc2,size_16,color_FFFFFF,t_70#pic_center" alt="sub2" style="zoom: 67%;" />
